{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 김기현의 자연어 처리 딥러닝 캠프 』</center>"
   ]
  },
  {{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 김기현의 자연어 처리 딥러닝 캠프 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/974/l9791162241974.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장. Hello 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#딥러닝을-시작하기-전에\" data-toc-modified-id=\"딥러닝을-시작하기-전에-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>딥러닝을 시작하기 전에</a></span></li><li><span><a href=\"#설치-방법\" data-toc-modified-id=\"설치-방법-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>설치 방법</a></span></li><li><span><a href=\"#짧은-튜토리얼\" data-toc-modified-id=\"짧은-튜토리얼-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>짧은 튜토리얼</a></span><ul class=\"toc-item\"><li><span><a href=\"#텐서\" data-toc-modified-id=\"텐서-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>텐서</a></span></li><li><span><a href=\"#Autograd\" data-toc-modified-id=\"Autograd-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Autograd</a></span></li><li><span><a href=\"#피드포워드\" data-toc-modified-id=\"피드포워드-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>피드포워드</a></span></li><li><span><a href=\"#nn.Module\" data-toc-modified-id=\"nn.Module-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>nn.Module</a></span></li><li><span><a href=\"#역전파-수행\" data-toc-modified-id=\"역전파-수행-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>역전파 수행</a></span></li><li><span><a href=\"#train()과-eval()\" data-toc-modified-id=\"train()과-eval()-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>train()과 eval()</a></span></li><li><span><a href=\"#선형회귀분석-예제\" data-toc-modified-id=\"선형회귀분석-예제-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>선형회귀분석 예제</a></span></li><li><span><a href=\"#GPU-사용하기\" data-toc-modified-id=\"GPU-사용하기-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>GPU 사용하기</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝을 시작하기 전에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 짧은 튜토리얼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 텐서는 넘파이의 배열인 ndarray와 같은 개념입니다. 파이토치에서 연산을 수행하기 위한 가장 기본적인 객체입니다. 파이토치는 텐서를 통해 값을 저장하고 그 값들에 대해 연산을 수행할 수 있는 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.707033Z",
     "start_time": "2021-01-21T06:17:30.331152Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.720996Z",
     "start_time": "2021-01-21T06:17:31.711023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.Tensor()** 는 Numpy array의 사본일 뿐입니다. 그래서 tensor의 값을 변경하더라도 Numpy array자체의 값이 달라지지 않습니다. 하지만 **torch.from_numpy()**는 자동으로 input array의 dtype을 상속받고 tensor와 메모리 버퍼를 공유하기 때문에 tensor의 값이 변경되면 Numpy array값이 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.755426Z",
     "start_time": "2021-01-21T06:17:31.727978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.780351Z",
     "start_time": "2021-01-21T06:17:31.762399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.810282Z",
     "start_time": "2021-01-21T06:17:31.792319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd는 자동으로 미분 및 역전파를 수행하는 기능입니다. 따라서 대부분 텐서 간 연산들을 크게 신경 쓸 필요 없이 역전파 알고리즘을 수행하는 명령어를 호출하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.822256Z",
     "start_time": "2021-01-21T06:17:31.814264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3664e-29,  4.5908e-41],\n",
       "        [ 0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.837198Z",
     "start_time": "2021-01-21T06:17:31.828223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  4.4766e+00],\n",
       "        [-3.4562e-29,  4.5908e-41]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.FloatTensor(2, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.849166Z",
     "start_time": "2021-01-21T06:17:31.841189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  4.4766e+00],\n",
       "        [-3.4562e-29,  4.5908e-41]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd를 활성화 시킴\n",
    "# 텐서에 대한 기울기를 저장하겠다는 의미\n",
    "y.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x와 y를 생성하고 둘을 더하는 연산을 수행하면 x + y에 해당하는 텐서가 생성되어 연산 그래프에 할당됩니다. 그리고 다시 생성된 텐서를 더해준 뒤, 이를 z에 할당합니다. 따라서 z로부터 역전파를 수행하면, 이미 생성된 연산 그래프를 따라서 미분 값을 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.864126Z",
     "start_time": "2021-01-21T06:17:31.851161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.7328e-29,  4.4766e+00],\n",
       "        [-3.4562e-29,  4.5908e-41]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (x + y) + torch.FloatTensor(2, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/L2muu/btqUkZMDmd0/Kco15I31krWjkxL7ZG3nj0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스와 텐서플로에서는 미리 정의한 연산들을 컴파일을 통해 고정한 후, 정해진 입력에 맞춰 텐서를 피드포워드해야 합니다. 반면 파이토치에는 정해진 연산이라는 것은 없고, 모델은 배워야 하는 파라미터 텐서만 미리 알고 있을 뿐, 그 가중치 파라미터들이 어떠한 연산을 통해 학습 또는 연산에 관여 하는지는 알 수 없습니다. 연산이 수행된 직후에 알 수 있을 뿐입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 음.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기울기를 구할 필요가 없는 연산의 경우**에는 다음과 같이 with 문법을 사용하여 연산을 수행할 수 있습니다. 역전파 알고리즘 수행이 필요 없는 비 학습 과정, 즉 **예측(prediction), 추론(inference)** 등을 수행할 때 유용하며, 기울기를 구하기 위한 (연산 그래프 생성 등의) 사전 작업을 생략할 수 있으므로 **연산 속도 및 메모리 사용 측면**에서도 큰 이점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피드포워드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 계층(linear layer)** 또는 **완전연결계층(fully-connected layer)**을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.877092Z",
     "start_time": "2021-01-21T06:17:31.867138Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x, W, b):\n",
    "    y = torch.mm(x, W) + b # torch.mm은 행렬곱\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.898036Z",
     "start_time": "2021-01-21T06:17:31.879086Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.0448e+18, -8.5496e+13, -3.2904e+22,  2.0226e+20, -3.3980e+22],\n",
       "        [-8.0451e+18, -8.5700e+13, -5.6809e+22,  1.6857e+20, -3.4063e+22],\n",
       "        [-8.0449e+18, -8.5716e+13, -5.6759e+22,  1.6865e+20, -3.4070e+22],\n",
       "        [-3.8495e+18, -8.5741e+13, -5.6829e+22,  1.7300e+20, -3.4080e+22],\n",
       "        [-8.0448e+18, -8.5700e+13, -5.6809e+22,  1.6857e+20, -3.4064e+22],\n",
       "        [-8.0422e+18, -1.1288e+12, -2.4577e+22,  1.6857e+20,  3.9404e+20],\n",
       "        [-1.0431e+17, -8.5715e+13, -5.6819e+22,  1.7696e+20, -3.4070e+22],\n",
       "        [-8.0409e+18, -8.5696e+13, -4.4311e+22,  1.8625e+20, -3.4062e+22],\n",
       "        [-7.9882e+18, -8.5702e+13, -3.2974e+22,  2.0234e+20, -3.4064e+22],\n",
       "        [-1.0368e+17, -8.5739e+13, -5.6825e+22,  1.7697e+20, -3.4079e+22],\n",
       "        [-8.0423e+18, -8.5493e+13, -3.2903e+22,  2.0227e+20, -3.3979e+22],\n",
       "        [-8.0424e+18, -8.5500e+13, -3.2905e+22,  2.0227e+20, -3.3982e+22],\n",
       "        [-8.0450e+18, -8.5700e+13, -5.6809e+22,  1.6857e+20, -3.4063e+22],\n",
       "        [-8.0447e+18, -8.5716e+13, -5.6830e+22,  1.6855e+20, -3.4070e+22],\n",
       "        [-8.0449e+18, -1.1299e+12, -7.4386e+20,  2.0227e+20,  3.9361e+20],\n",
       "        [-6.8025e+18, -8.5748e+13, -5.6840e+22,  1.6987e+20, -3.4083e+22]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "W = torch.FloatTensor(10, 5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x, W, b)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 수식을 더 편리하고 깔끔하게 구현하는 방법을 살펴봅니다. **nn.Module**이라는 클래스를 제공하여 사용자가 그 위에서 필요한 모델 구조를 구현할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Module 상속 객체 안에 nn.Module 상속 객체를 선언하여 변수로 사용할 수 있음\n",
    "- nn.Module의 forward() 함수를 오버라이드(override)하여 피드포워드 구현할 수 있음\n",
    "- nn.Module의 특징을 이용하여 한 번에 신경망 가중치 파라미터들을 저장 및 불러오기를 수행할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.904020Z",
     "start_time": "2021-01-21T06:17:31.900031Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.915989Z",
     "start_time": "2021-01-21T06:17:31.908009Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 원소를 가진 벡터 16개를 가진 행렬 x를 생성하고, MyLinear 클래스의 객체인 linear에 통과시킵니다. 그럼 10개 원소를 가진 벡터는 5개의 원소를 가진 벡터로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.926958Z",
     "start_time": "2021-01-21T06:17:31.918980Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.949898Z",
     "start_time": "2021-01-21T06:17:31.933941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4997e+19, -3.3169e+25, -2.5828e+22, -2.3047e+22, -8.0952e+21],\n",
       "        [-4.6283e+17, -3.3180e+25, -1.7678e+22, -3.3657e+20, -8.0980e+21],\n",
       "        [-3.3593e+19, -4.2589e+23, -2.5775e+22, -2.9703e+20, -1.0499e+20],\n",
       "        [-4.5146e+17, -4.4487e+23,  1.6120e+22, -3.0357e+20, -8.0939e+21],\n",
       "        [-4.6275e+17, -4.3725e+23,  1.6144e+22, -3.3609e+20, -1.1792e+20],\n",
       "        [-4.6105e+17, -4.3723e+23,  1.6144e+22, -3.0346e+20, -1.0658e+20],\n",
       "        [-1.7476e+19, -3.2946e+25, -3.7927e+21, -2.2980e+22, -8.0737e+21],\n",
       "        [-3.4899e+19, -3.3085e+25, -2.5706e+22, -2.2982e+22, -8.0744e+21],\n",
       "        [-3.4979e+19, -3.3086e+25, -2.5806e+22, -2.3035e+22, -8.0933e+21],\n",
       "        [-3.4980e+19, -3.3163e+25, -2.5807e+22, -2.3035e+22, -8.0935e+21],\n",
       "        [-3.4981e+19, -3.3163e+25, -2.5808e+22, -2.3036e+22, -8.0938e+21],\n",
       "        [-3.4986e+19, -3.3164e+25, -2.5815e+22, -2.3040e+22, -8.0950e+21],\n",
       "        [-3.4988e+19, -3.3169e+25, -2.5816e+22, -2.3046e+22, -8.0952e+21],\n",
       "        [-3.4997e+19, -3.3179e+25, -2.5828e+22, -2.3047e+22, -8.0975e+21],\n",
       "        [-3.4998e+19, -3.3180e+25, -2.5829e+22, -2.3047e+22, -8.0977e+21],\n",
       "        [-2.1773e+19, -3.3180e+25, -2.2715e+22, -1.4338e+22, -8.0979e+21]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parameters()** 함수는 모듈 내에 선언된 학습이 필요한 파라미터들을 반환하는 이터레이터(iterator)입니다. 이제 linear 모듈 내의 학습이 필요한 파라미터들의 크기를 **size()** 함수를 통해 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.960867Z",
     "start_time": "2021-01-21T06:17:31.953887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈 리스트가 찍혔다는 것은 linear 모듈 내에는 **학습 가능한 파라미터가 없다**는 이야기입니다. 신경망의 학습 파라미터는 단순한 텐서가 아니기 때문에 파라미터로 등록되어야 합니다.  \n",
    "\n",
    "따라서 우리는 **Parameter**라는 클래스를 사용하여 텐서를 감싸야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.971845Z",
     "start_time": "2021-01-21T06:17:31.963861Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:31.985802Z",
     "start_time": "2021-01-21T06:17:31.974830Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:32.001759Z",
     "start_time": "2021-01-21T06:17:31.988793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 5]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 nn.Module을 상속받은 클래스는 nn.Module의 자식 클래스를 멤버 변수로 가질 수 있다고 했습니다. 따라서 nn.Linear 클래스를 사용하여 W와 b를 대체했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:32.013727Z",
     "start_time": "2021-01-21T06:17:32.005749Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size) # nn.Linear은 선형 회귀 모델\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:17:32.027690Z",
     "start_time": "2021-01-21T06:17:32.016718Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinear(\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear = MyLinear(10, 5)\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train()과 eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀분석 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/974/l9791162241974.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장. Hello 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#딥러닝을-시작하기-전에\" data-toc-modified-id=\"딥러닝을-시작하기-전에-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>딥러닝을 시작하기 전에</a></span></li><li><span><a href=\"#설치-방법\" data-toc-modified-id=\"설치-방법-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>설치 방법</a></span></li><li><span><a href=\"#짧은-튜토리얼\" data-toc-modified-id=\"짧은-튜토리얼-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>짧은 튜토리얼</a></span><ul class=\"toc-item\"><li><span><a href=\"#텐서\" data-toc-modified-id=\"텐서-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>텐서</a></span></li><li><span><a href=\"#Autograd\" data-toc-modified-id=\"Autograd-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Autograd</a></span></li><li><span><a href=\"#피드포워드\" data-toc-modified-id=\"피드포워드-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>피드포워드</a></span></li><li><span><a href=\"#nn.Module\" data-toc-modified-id=\"nn.Module-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>nn.Module</a></span></li><li><span><a href=\"#역전파-수행\" data-toc-modified-id=\"역전파-수행-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>역전파 수행</a></span></li><li><span><a href=\"#train()과-eval()\" data-toc-modified-id=\"train()과-eval()-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>train()과 eval()</a></span></li><li><span><a href=\"#선형회귀분석-예제\" data-toc-modified-id=\"선형회귀분석-예제-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>선형회귀분석 예제</a></span></li><li><span><a href=\"#GPU-사용하기\" data-toc-modified-id=\"GPU-사용하기-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>GPU 사용하기</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝을 시작하기 전에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 짧은 튜토리얼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치의 텐서는 넘파이의 배열인 ndarray와 같은 개념입니다. 파이토치에서 연산을 수행하기 위한 가장 기본적인 객체입니다. 파이토치는 텐서를 통해 값을 저장하고 그 값들에 대해 연산을 수행할 수 있는 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:00.837693Z",
     "start_time": "2021-01-21T06:14:59.544901Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:00.851655Z",
     "start_time": "2021-01-21T06:15:00.841682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.Tensor()** 는 Numpy array의 사본일 뿐입니다. 그래서 tensor의 값을 변경하더라도 Numpy array자체의 값이 달라지지 않습니다. 하지만 **torch.from_numpy()**는 자동으로 input array의 dtype을 상속받고 tensor와 메모리 버퍼를 공유하기 때문에 tensor의 값이 변경되면 Numpy array값이 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:00.879581Z",
     "start_time": "2021-01-21T06:15:00.855646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.265044Z",
     "start_time": "2021-01-21T06:15:00.884569Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3da1455aa595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1, 2], [3, 4]]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.275018Z",
     "start_time": "2021-01-21T06:14:59.548Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd는 자동으로 미분 및 역전파를 수행하는 기능입니다. 따라서 대부분 텐서 간 연산들을 크게 신경 쓸 필요 없이 역전파 알고리즘을 수행하는 명령어를 호출하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.277013Z",
     "start_time": "2021-01-21T06:14:59.558Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.279007Z",
     "start_time": "2021-01-21T06:14:59.564Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(2, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.281002Z",
     "start_time": "2021-01-21T06:14:59.569Z"
    }
   },
   "outputs": [],
   "source": [
    "# autograd를 활성화 시킴\n",
    "# 텐서에 대한 기울기를 저장하겠다는 의미\n",
    "y.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x와 y를 생성하고 둘을 더하는 연산을 수행하면 x + y에 해당하는 텐서가 생성되어 연산 그래프에 할당됩니다. 그리고 다시 생성된 텐서를 더해준 뒤, 이를 z에 할당합니다. 따라서 z로부터 역전파를 수행하면, 이미 생성된 연산 그래프를 따라서 미분 값을 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.281999Z",
     "start_time": "2021-01-21T06:14:59.574Z"
    }
   },
   "outputs": [],
   "source": [
    "z = (x + y) + torch.FloatTensor(2, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/L2muu/btqUkZMDmd0/Kco15I31krWjkxL7ZG3nj0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스와 텐서플로에서는 미리 정의한 연산들을 컴파일을 통해 고정한 후, 정해진 입력에 맞춰 텐서를 피드포워드해야 합니다. 반면 파이토치에는 정해진 연산이라는 것은 없고, 모델은 배워야 하는 파라미터 텐서만 미리 알고 있을 뿐, 그 가중치 파라미터들이 어떠한 연산을 통해 학습 또는 연산에 관여 하는지는 알 수 없습니다. 연산이 수행된 직후에 알 수 있을 뿐입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 음.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기울기를 구할 필요가 없는 연산의 경우**에는 다음과 같이 with 문법을 사용하여 연산을 수행할 수 있습니다. 역전파 알고리즘 수행이 필요 없는 비 학습 과정, 즉 **예측(prediction), 추론(inference)** 등을 수행할 때 유용하며, 기울기를 구하기 위한 (연산 그래프 생성 등의) 사전 작업을 생략할 수 있으므로 **연산 속도 및 메모리 사용 측면**에서도 큰 이점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피드포워드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 계층(linear layer)** 또는 **완전연결계층(fully-connected layer)**을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.284991Z",
     "start_time": "2021-01-21T06:14:59.584Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x, W, b):\n",
    "    y = torch.mm(x, W) + b # torch.mm은 행렬곱\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.286996Z",
     "start_time": "2021-01-21T06:14:59.590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(16, 10)\n",
    "W = torch.FloatTensor(10, 5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x, W, b)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 수식을 더 편리하고 깔끔하게 구현하는 방법을 살펴봅니다. **nn.Module**이라는 클래스를 제공하여 사용자가 그 위에서 필요한 모델 구조를 구현할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Module 상속 객체 안에 nn.Module 상속 객체를 선언하여 변수로 사용할 수 있음\n",
    "- nn.Module의 forward() 함수를 오버라이드(override)하여 피드포워드 구현할 수 있음\n",
    "- nn.Module의 특징을 이용하여 한 번에 신경망 가중치 파라미터들을 저장 및 불러오기를 수행할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.288980Z",
     "start_time": "2021-01-21T06:14:59.594Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.290975Z",
     "start_time": "2021-01-21T06:14:59.600Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 원소를 가진 벡터 16개를 가진 행렬 x를 생성하고, MyLinear 클래스의 객체인 linear에 통과시킵니다. 그럼 10개 원소를 가진 벡터는 5개의 원소를 가진 벡터로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.291973Z",
     "start_time": "2021-01-21T06:14:59.607Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.295499Z",
     "start_time": "2021-01-21T06:14:59.611Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**parameters()** 함수는 모듈 내에 선언된 학습이 필요한 파라미터들을 반환하는 이터레이터(iterator)입니다. 이제 linear 모듈 내의 학습이 필요한 파라미터들의 크기를 **size()** 함수를 통해 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.297474Z",
     "start_time": "2021-01-21T06:14:59.615Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빈 리스트가 찍혔다는 것은 linear 모듈 내에는 **학습 가능한 파라미터가 없다**는 이야기입니다. 신경망의 학습 파라미터는 단순한 텐서가 아니기 때문에 파라미터로 등록되어야 합니다.  \n",
    "\n",
    "따라서 우리는 **Parameter**라는 클래스를 사용하여 텐서를 감싸야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.298471Z",
     "start_time": "2021-01-21T06:14:59.625Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.300467Z",
     "start_time": "2021-01-21T06:14:59.628Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = torch.FloatTensor(16, 10)\n",
    "linear = MyLinear(10, 5)\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.302460Z",
     "start_time": "2021-01-21T06:14:59.632Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 nn.Module을 상속받은 클래스는 nn.Module의 자식 클래스를 멤버 변수로 가질 수 있다고 했습니다. 따라서 nn.Linear 클래스를 사용하여 W와 b를 대체했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.305452Z",
     "start_time": "2021-01-21T06:14:59.639Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size): \n",
    "        super(MyLinear, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size) # nn.Linear은 선형 회귀 모델\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T06:15:01.308445Z",
     "start_time": "2021-01-21T06:14:59.644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear = MyLinear(10, 5)\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train()과 eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀분석 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
