{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 김기현의 자연어 처리 딥러닝 캠프 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/974/l9791162241974.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장. 딥러닝을 활용한 자연어 처리 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#자연어-처리란-무엇일까?\" data-toc-modified-id=\"자연어-처리란-무엇일까?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>자연어 처리란 무엇일까?</a></span><ul class=\"toc-item\"><li><span><a href=\"#자연어-처리(NLP,-natural-language-processing)\" data-toc-modified-id=\"자연어-처리(NLP,-natural-language-processing)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>자연어 처리(NLP, natural language processing)</a></span></li><li><span><a href=\"#자연어-처리의-최종-목표\" data-toc-modified-id=\"자연어-처리의-최종-목표-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>자연어 처리의 최종 목표</a></span></li><li><span><a href=\"#대표적인-과제-또는-응용-분야\" data-toc-modified-id=\"대표적인-과제-또는-응용-분야-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>대표적인 과제 또는 응용 분야</a></span></li></ul></li><li><span><a href=\"#딥러닝-소개\" data-toc-modified-id=\"딥러닝-소개-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>딥러닝 소개</a></span><ul class=\"toc-item\"><li><span><a href=\"#딥러닝의-역사\" data-toc-modified-id=\"딥러닝의-역사-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>딥러닝의 역사</a></span></li><li><span><a href=\"#자연어-처리의-패러다임-변화\" data-toc-modified-id=\"자연어-처리의-패러다임-변화-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>자연어 처리의 패러다임 변화</a></span></li></ul></li><li><span><a href=\"#왜-자연어-처리는-어려울까?\" data-toc-modified-id=\"왜-자연어-처리는-어려울까?-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>왜 자연어 처리는 어려울까?</a></span><ul class=\"toc-item\"><li><span><a href=\"#모호성\" data-toc-modified-id=\"모호성-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>모호성</a></span></li><li><span><a href=\"#다양한-표현\" data-toc-modified-id=\"다양한-표현-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>다양한 표현</a></span></li><li><span><a href=\"#불연속적-데이터\" data-toc-modified-id=\"불연속적-데이터-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>불연속적 데이터</a></span></li></ul></li><li><span><a href=\"#무엇이-한국어-자연어-처리를-더욱-어렵게-만들까?\" data-toc-modified-id=\"무엇이-한국어-자연어-처리를-더욱-어렵게-만들까?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>무엇이 한국어 자연어 처리를 더욱 어렵게 만들까?</a></span><ul class=\"toc-item\"><li><span><a href=\"#교착어\" data-toc-modified-id=\"교착어-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>교착어</a></span></li><li><span><a href=\"#띄어쓰기\" data-toc-modified-id=\"띄어쓰기-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>띄어쓰기</a></span></li><li><span><a href=\"#평서문과-의문문\" data-toc-modified-id=\"평서문과-의문문-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>평서문과 의문문</a></span></li><li><span><a href=\"#주어-생략\" data-toc-modified-id=\"주어-생략-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>주어 생략</a></span></li><li><span><a href=\"#한자-기반의-언어\" data-toc-modified-id=\"한자-기반의-언어-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>한자 기반의 언어</a></span></li></ul></li><li><span><a href=\"#자연어-처리의-최근-추세\" data-toc-modified-id=\"자연어-처리의-최근-추세-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>자연어 처리의 최근 추세</a></span><ul class=\"toc-item\"><li><span><a href=\"#딥러닝의-자연어-처리-정복-과정\" data-toc-modified-id=\"딥러닝의-자연어-처리-정복-과정-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>딥러닝의 자연어 처리 정복 과정</a></span></li><li><span><a href=\"#자연어-생성의-시작\" data-toc-modified-id=\"자연어-생성의-시작-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>자연어 생성의 시작</a></span></li><li><span><a href=\"#메모리를-활용한-심화-연구\" data-toc-modified-id=\"메모리를-활용한-심화-연구-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>메모리를 활용한 심화 연구</a></span></li><li><span><a href=\"#강화학습의-자연어-처리-분야에-대한-성공적인-적용\" data-toc-modified-id=\"강화학습의-자연어-처리-분야에-대한-성공적인-적용-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>강화학습의 자연어 처리 분야에 대한 성공적인 적용</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 처리란 무엇일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리(NLP, natural language processing)\n",
    "인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 묘사할 수 있도록 연구하고 이를 구현하는 인공지능의 한 분야  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/coSsbK/btqT90zru4T/m6pkGcxRecEPLbtGR4CNl1/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리의 최종 목표\n",
    "컴퓨터가 사람의 언어를 이해하고 여러 가지 문제를 수행할 수 있도록 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대표적인 과제 또는 응용 분야 \n",
    "- 감성 분석(sentiment analysis)\n",
    "- 사용자의 의도 파악 및 대화에 도움을 주는 작업 ex) 애플의 시리, 아마존의 알렉사\n",
    "- 요약(summarization), 기계 번역(translate)\n",
    "- 사용자로부터 입력을 받아 사용자가 원하는 것을 검색 및 답변을 주는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 먼저 두각을 나타낸 분야는 이미지 분류 문제인 이미지넷(ImageNet) 대회였지만 가장 먼저 상용화 부문에서 빛을 본 분야는 음성 인식 쪽이었습니다.  \n",
    "\n",
    "상대적으로 가장 나중에 빛을 본 곳은 **자연어 처리 분야**였습니다. 이미지나 음성과 달리, 단어 간의 순서 및 상호 정보가 반영된 **시퀀셜 데이터(sequential data)**라는 점이 더 큰 장벽으로 다가왔을 것입니다. 하지만, **어텐션 메커니즘**의 등장으로 인해서 기계번역 분야마저 딥러닝에 의해 정복되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 음성은 시퀀셜 데이터가 아닌가?  \n",
    "A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝의 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2010년 이전**  \n",
    "\n",
    "- 1950년(첫 번째 황금기): 인공지능이 처음 거론됨  \n",
    "- 1980년(두 번째 황금기): 역전파(back propagation) 알고리즘 제안\n",
    "- 2006년: 네트워크라 불리는 심층 신뢰 신경망(DBN, deep belief network)을 통해 여러 층의 은닉층(hidden layer)을 효과적으로 사전훈련(pretraining)시킬 방법 제시\n",
    "\n",
    "**2012년**  \n",
    "이미지넷에서 인공 신경망을 이용한 **AlexNet** 등장  \n",
    "음성 인식 분야에서 2012년 GMM을 DNN으로 대체하며 혁명  \n",
    "\n",
    "**2015년**  \n",
    "**residual connection을 활용한 RseNet 등장**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**기계번역 분야는?**\n",
    "\n",
    "---\n",
    "\n",
    "- **딥러닝 이전의 기계번역**  \n",
    "통계 기반 기계번역(SMT, sstatistical machine translation)이 지배  \n",
    "(but. 매우 복잡한 구조)  \n",
    "https://m.blog.naver.com/PostView.nhn?blogId=bcj1210&logNo=221581535580&proxyReferer=https:%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/4O88j/btqUfZl0uiI/wNTwC2WN3RJlfKQPm9K52K/img.png\" width=70%>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2014년 이후**  \n",
    "**seq2seq** 모델 구조가 등장하며 end-to-end 신경망 기반 기계 번역(NMT, neural machine translation)의 시대  \n",
    "seq2seq을 기반으로 **어텐션 메커니즘(attention mechanism)이 제안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/5T2qn/btqUhA7nwHz/9baKXYNN7CKFzSEEudrKzK/img.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리의 패러다임 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 이전의 기존 자연어 처리 애플리케이션의 전형적인 구조는 다음 그림과 같습니다.  \n",
    "하지만 여러 가지 단계의 모듈로 구성되어 디자인이 복잡하고, 문제에 따라서는 또 다른 서브 모듈이 추가되기도 합니다. 따라서 **매우 무겁고 복잡+*하여 구현 및 시스템 구성이 어려웠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/cJ8TtH/btqT90Gf7m7/rjYV2GikCXdxgbaIjqC1Qk/img.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝이 등장하며 점차 end-to-end 모델로 대체되었습니다. 여전히 챗봇을 비롯한 많은 문제에서 end-to-end 학습이 이루어지지 않고 있지만, 최종적으로는 end-to-end 모델이 제안될 것이라 볼 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/efeVts/btqUeWpBUei/zjlDz37mqgZqxCXVcsQNo1/img.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왜 자연어 처리는 어려울까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모호성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어의 중의성  \n",
    "- 문장 내 정보의 부족  \n",
    "- 구조 해석의 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장의 표현 형식은 다양하고, 비슷한 의미의 단어들이 존재하기 때문에 다양한 표현의 문제가 존재합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불연속적 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 불연속적(discrete)인 데이터이므로 과거에는 비교적 처리가 쉬운 편이었습니다. 하지만 딥러닝에 적용하려면 연속적인 값으로 바꾸어주어야 합니다. 자연어 처리에서는 **단어 임베딩**이 그 역할을 수행합니다.  \n",
    "\n",
    "불연속적인 데이터이기 때문에 많은 종류의 데이터를 표현하려면 데이터 종류만큼의 **엄청난 차원**이 필요합니다. 또한, 단어가 살짝만 바뀌어도 문장의 의미가 완전히 다르게 변할 수도 있습니다. 띄어쓰기나 어순의 차이로 인한 정제(normalizaiton)의 이슈도 큰 어려움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무엇이 한국어 자연어 처리를 더욱 어렵게 만들까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교착어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한국어는 어간에 접사가 붙어 단어를 이루고 의미와 문법적 기능이 정해지는 **교착어**에 속합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄어쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄어쓰기에 대한 표준이 계속 바뀌어 왔기 때문에 사람마다 띄어쓰기를 하는 것이 다를뿐더러, 심지어는 띄어쓰기가 아예 없더라도 해석이 가능합니다. 추가적인 분절을 통해 띄어쓰기를 정제해주는 과정이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평서문과 의문문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 한국어에도 의문문을 나타낼 수 있는 접사가 있습니다. 하지만 많은 경우 한국어는 의문문과 평서문이 같은 형태의 문장 구조를 가지는 것이 사실입니다. 따라서 마침표나 물음표가 붙지 않으면 알 수 없는 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주어 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사가 중요시되어 주어가 자주 생략되는 경우가 없는 영어와 달리, 한국어는 동사를 중요시하기에 주어가 자주 생략됩니다. 기계번역을 비롯하여 문장의 정확한 의미를 파악하기가 매우 어려워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한자 기반의 언어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 처리의 최근 추세"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝의 자연어 처리 정복 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 생성의 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메모리를 활용한 심화 연구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습의 자연어 처리 분야에 대한 성공적인 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
